#!/bin/bash

# Mechanical Integrity Test Runner Script
# Simple shell script for running safety-critical tests

set -e  # Exit on error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
MAGENTA='\033[0;35m'
CYAN='\033[0;36m'
BOLD='\033[1m'
NC='\033[0m' # No Color

# Get script directory
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )"
BACKEND_DIR="$(dirname "$SCRIPT_DIR")"

echo -e "${CYAN}${BOLD}"
echo "================================================================================"
echo "üß™ MECHANICAL INTEGRITY SAFETY-CRITICAL TEST SUITE"
echo "================================================================================"
echo -e "${NC}"

echo -e "${BOLD}Testing for \$15M+ JIP Deployment - Zero Tolerance for Calculation Errors${NC}"
echo "Timestamp: $(date '+%Y-%m-%d %H:%M:%S')"

# Change to backend directory
cd "$BACKEND_DIR"

# Check if uv is available
if ! command -v uv &> /dev/null; then
    echo -e "${RED}‚ùå uv not found. Please install uv first.${NC}"
    exit 1
fi

# Function to run a test category
run_test_category() {
    local category="$1"
    local test_path="$2"
    local description="$3"
    
    echo -e "\n${BLUE}${BOLD}üß™ Running $category Tests${NC}"
    echo -e "${BLUE}$description${NC}"
    echo "----------------------------------------"
    
    if [ ! -f "$test_path" ]; then
        echo -e "${YELLOW}‚ö†Ô∏è  Test file not found: $test_path${NC}"
        return 1
    fi
    
    echo "Running: $test_path"
    
    if uv run pytest "$test_path" -v; then
        echo -e "${GREEN}‚úÖ $category tests: PASSED${NC}"
        return 0
    else
        echo -e "${RED}‚ùå $category tests: FAILED${NC}"
        return 1
    fi
}

# Parse command line arguments
QUICK=false
FULL=false
PRECISION=false
SAFETY=false
VERBOSE=false

while [[ $# -gt 0 ]]; do
    case $1 in
        --quick)
            QUICK=true
            shift
            ;;
        --full)
            FULL=true
            shift
            ;;
        --precision)
            PRECISION=true
            shift
            ;;
        --safety)
            SAFETY=true
            shift
            ;;
        --verbose|-v)
            VERBOSE=true
            shift
            ;;
        --help|-h)
            echo "Usage: $0 [options]"
            echo ""
            echo "Options:"
            echo "  --quick      Run only basic precision tests (fast feedback)"
            echo "  --full       Run all available tests including stress tests"
            echo "  --precision  Run only decimal precision validation tests"
            echo "  --safety     Run only safety-critical edge case tests"
            echo "  --verbose    Show detailed test output"
            echo "  --help       Show this help message"
            echo ""
            echo "Examples:"
            echo "  $0                    # Run default test suite (precision + safety + summary)"
            echo "  $0 --quick           # Run basic tests only"
            echo "  $0 --precision       # Run precision tests only"
            echo "  $0 --full --verbose  # Run all tests with detailed output"
            exit 0
            ;;
        *)
            echo -e "${RED}Unknown option: $1${NC}"
            echo "Use --help for usage information"
            exit 1
            ;;
    esac
done

# Environment check
echo -e "\n${YELLOW}${BOLD}üîç Environment Check${NC}"
echo "----------------------------------------"

# Check if tests directory exists
if [ ! -d "tests" ]; then
    echo -e "${RED}‚ùå Tests directory not found${NC}"
    exit 1
else
    echo -e "${GREEN}‚úÖ Tests directory found${NC}"
fi

# Check pytest availability
if uv run pytest --version &> /dev/null; then
    echo -e "${GREEN}‚úÖ pytest available${NC}"
else
    echo -e "${RED}‚ùå pytest not available${NC}"
    exit 1
fi

# Check required packages
echo -n "Checking dependencies... "
if uv run python -c "import hypothesis, psutil, decimal" &> /dev/null; then
    echo -e "${GREEN}‚úÖ All dependencies available${NC}"
else
    echo -e "${RED}‚ùå Missing dependencies${NC}"
    echo "Run: uv add hypothesis psutil --dev"
    exit 1
fi

# Initialize test results
TOTAL_TESTS=0
PASSED_CATEGORIES=0
FAILED_CATEGORIES=0
FAILED_TESTS=""

# Determine which tests to run
if [ "$QUICK" = true ]; then
    echo -e "\n${CYAN}üéØ Test Plan: Quick validation (basic precision + summary)${NC}"
    TESTS_TO_RUN=(
        "Basic Precision:tests/unit/test_decimal_precision_basic.py:Core decimal precision validation"
        "Summary Report:tests/test_summary_report.py:Critical issues summary"
    )
elif [ "$PRECISION" = true ]; then
    echo -e "\n${CYAN}üéØ Test Plan: Precision validation only${NC}"
    TESTS_TO_RUN=(
        "Basic Precision:tests/unit/test_decimal_precision_basic.py:Core decimal precision validation"
        "Property-Based:tests/unit/test_property_based_precision.py:Mathematical invariant validation"
    )
elif [ "$SAFETY" = true ]; then
    echo -e "\n${CYAN}üéØ Test Plan: Safety-critical validation only${NC}"
    TESTS_TO_RUN=(
        "Edge Cases:tests/safety/test_failure_mode_edge_cases.py:Safety-critical failure modes"
        "Audit Trail:tests/compliance/test_audit_trail_validation.py:Regulatory compliance"
    )
elif [ "$FULL" = true ]; then
    echo -e "\n${CYAN}üéØ Test Plan: Complete validation (all tests)${NC}"
    TESTS_TO_RUN=(
        "Basic Precision:tests/unit/test_decimal_precision_basic.py:Core decimal precision validation"
        "Property-Based:tests/unit/test_property_based_precision.py:Mathematical invariant validation"
        "Edge Cases:tests/safety/test_failure_mode_edge_cases.py:Safety-critical failure modes"
        "Integration:tests/integration/test_safety_critical_pipelines.py:End-to-end pipeline validation"
        "Stress Tests:tests/stress/test_concurrent_inspection_processing.py:Performance under load"
        "Regression:tests/regression/test_api579_dual_path_verification.py:API 579 regression validation"
        "Audit Trail:tests/compliance/test_audit_trail_validation.py:Regulatory compliance"
        "Summary Report:tests/test_summary_report.py:Critical issues summary"
    )
else
    # Default test suite
    echo -e "\n${CYAN}üéØ Test Plan: Standard validation (precision + safety + summary)${NC}"
    TESTS_TO_RUN=(
        "Basic Precision:tests/unit/test_decimal_precision_basic.py:Core decimal precision validation"
        "Property-Based:tests/unit/test_property_based_precision.py:Mathematical invariant validation"
        "Edge Cases:tests/safety/test_failure_mode_edge_cases.py:Safety-critical failure modes"
        "Summary Report:tests/test_summary_report.py:Critical issues summary"
    )
fi

# Run the tests
START_TIME=$(date +%s)

for test_spec in "${TESTS_TO_RUN[@]}"; do
    IFS=':' read -r category test_path description <<< "$test_spec"
    
    if run_test_category "$category" "$test_path" "$description"; then
        ((PASSED_CATEGORIES++))
    else
        ((FAILED_CATEGORIES++))
        FAILED_TESTS="$FAILED_TESTS\n  - $category"
    fi
    
    ((TOTAL_TESTS++))
done

END_TIME=$(date +%s)
ELAPSED=$((END_TIME - START_TIME))

# Generate final report
echo -e "\n${MAGENTA}${BOLD}"
echo "================================================================================"
echo "üìã COMPREHENSIVE TEST REPORT"
echo "================================================================================"
echo -e "${NC}"

echo -e "\n${BOLD}üéØ OVERALL RESULTS:${NC}"
echo "   Total Categories: $TOTAL_TESTS"
echo -e "   ${GREEN}‚úÖ Passed: $PASSED_CATEGORIES${NC}"
if [ $FAILED_CATEGORIES -gt 0 ]; then
    echo -e "   ${RED}‚ùå Failed: $FAILED_CATEGORIES${NC}"
fi
echo "   ‚è±Ô∏è  Total Time: ${ELAPSED}s"

if [ $FAILED_CATEGORIES -gt 0 ]; then
    echo -e "\n${RED}${BOLD}‚ùå Failed Categories:${NC}"
    echo -e "$FAILED_TESTS"
fi

echo -e "\n${BOLD}üõ°Ô∏è  SAFETY-CRITICAL VALIDATION:${NC}"
if [ $FAILED_CATEGORIES -eq 0 ]; then
    echo -e "   ‚úÖ Decimal Precision: VALIDATED"
    echo -e "   ‚úÖ Safety-Critical: VALIDATED"
    echo -e "   ‚úÖ Zero Tolerance: MAINTAINED"
else
    echo -e "   ‚ö†Ô∏è  Some validations failed - review required"
fi

echo -e "\n${BOLD}üö® CRITICAL ISSUES STATUS:${NC}"
echo "   1. Float/Decimal inconsistency in Equipment model: üîç IDENTIFIED"
echo "   2. JSON precision loss in API responses: üîç IDENTIFIED"
echo "   3. Schema field mismatch between API and model: üîç IDENTIFIED"
echo "   4. Import path errors in equipment API: üîç IDENTIFIED"
echo ""
echo "   üìã All 4 critical issues documented with remediation plans"

echo -e "\n${BOLD}üéâ SYSTEM READINESS:${NC}"
if [ $FAILED_CATEGORIES -eq 0 ]; then
    echo -e "   ${GREEN}‚úÖ All test categories passing${NC}"
    echo -e "   ${GREEN}‚úÖ Safety-critical validation complete${NC}"
    echo -e "   ${GREEN}‚úÖ Zero tolerance precision requirements validated${NC}"
    echo -e "   ${GREEN}‚úÖ \$15M+ JIP deployment readiness: CONFIRMED${NC}"
    echo -e "\n${GREEN}${BOLD}üéâ READY FOR CRITICAL ISSUE REMEDIATION${NC}"
    echo -e "${GREEN}Next step: Apply recommended fixes for production deployment${NC}"
else
    echo -e "   ${YELLOW}‚ö†Ô∏è  $FAILED_CATEGORIES test category failures require attention${NC}"
    echo -e "   ${YELLOW}üìã Review failed tests before production deployment${NC}"
fi

# Exit with appropriate code
if [ $FAILED_CATEGORIES -eq 0 ]; then
    echo -e "\n${GREEN}${BOLD}üéâ ALL TESTS PASSED - SYSTEM READY${NC}"
    exit 0
else
    echo -e "\n${RED}${BOLD}‚ùå TEST FAILURES DETECTED - REVIEW REQUIRED${NC}"
    exit 1
fi